{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_URL = \"http://localhost:8890/lab/tree/Desktop/Code/final_project_twitter/server/tweet3.csv\"\n",
    "\n",
    "train_file_path = tf.keras.utils.get_file(\"tweets3.csv\", TRAIN_DATA_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(train_file_path, usecols=['text', 'replies', 'favorites', 'retweets','percentage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0       0\n1       0\n2       0\n3       0\n4       0\n       ..\n6257    1\n6258    1\n6259    1\n6260    1\n6261    1\nName: username, Length: 6262, dtype: int8\n"
    }
   ],
   "source": [
    "df['username'] = pd.Categorical(df['username'])\n",
    "df['username'] = df.username.cat.codes\n",
    "print(df['username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   username  replies  retweets  favorites  percentage\n0         0    543.0    2453.0    11891.0    4.566479\n1         0    396.0    1551.0     5655.0    7.002653\n2         0   3148.0   13208.0   180860.0    1.740573\n3         0    432.0    2579.0    11220.0    3.850267\n4         0    436.0    4157.0    24138.0    1.806281",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>username</th>\n      <th>replies</th>\n      <th>retweets</th>\n      <th>favorites</th>\n      <th>percentage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>543.0</td>\n      <td>2453.0</td>\n      <td>11891.0</td>\n      <td>4.566479</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>396.0</td>\n      <td>1551.0</td>\n      <td>5655.0</td>\n      <td>7.002653</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>3148.0</td>\n      <td>13208.0</td>\n      <td>180860.0</td>\n      <td>1.740573</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>432.0</td>\n      <td>2579.0</td>\n      <td>11220.0</td>\n      <td>3.850267</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>436.0</td>\n      <td>4157.0</td>\n      <td>24138.0</td>\n      <td>1.806281</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = df.pop('username')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((df.values, username.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Features: [5.43000000e+02 2.45300000e+03 1.18910000e+04 4.56647885e+00], Target: 0\nFeatures: [ 396.         1551.         5655.            7.00265252], Target: 0\nFeatures: [3.14800000e+03 1.32080000e+04 1.80860000e+05 1.74057282e+00], Target: 0\nFeatures: [4.32000000e+02 2.57900000e+03 1.12200000e+04 3.85026738e+00], Target: 0\nFeatures: [4.36000000e+02 4.15700000e+03 2.41380000e+04 1.80628055e+00], Target: 0\n"
    }
   ],
   "source": [
    "for feat, targ in dataset.take(5):\n",
    "  print ('Features: {}, Target: {}'.format(feat, targ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: id=340400, shape=(6262,), dtype=float64, numpy=\narray([ 4.56647885,  7.00265252,  1.74057282, ..., 45.29353655,\n       21.64329301, 38.02971373])>"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "tf.constant(df['percentage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.shuffle(len(df)).batch(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'train_stats' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-d92bb5352ed4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtrain_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtrain_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'std'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnormed_train_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mnormed_test_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-d92bb5352ed4>\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtrain_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtrain_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'std'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnormed_train_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnormed_test_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_stats' is not defined"
     ]
    }
   ],
   "source": [
    "def norm(x):\n",
    "  return (x - train_stats['mean']) / train_stats['std']\n",
    "normed_train_data = norm(train_dataset)\n",
    "normed_test_data = norm(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model():\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:Layer sequential_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n\nIf you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n\nTo change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n\nEpoch 1/15\n1253/1253 [==============================] - 23s 18ms/step - loss: 156.0823 - accuracy: 0.7328\nEpoch 2/15\n1253/1253 [==============================] - 9s 8ms/step - loss: 13.1979 - accuracy: 0.8073\nEpoch 3/15\n1253/1253 [==============================] - 6s 5ms/step - loss: 12.1052 - accuracy: 0.8323\nEpoch 4/15\n1253/1253 [==============================] - 8s 7ms/step - loss: 9.5675 - accuracy: 0.8684\nEpoch 5/15\n1253/1253 [==============================] - 7s 5ms/step - loss: 10.8902 - accuracy: 0.8718\nEpoch 6/15\n1253/1253 [==============================] - 6s 5ms/step - loss: 6.0068 - accuracy: 0.9015\nEpoch 7/15\n1253/1253 [==============================] - 7s 6ms/step - loss: 3.8095 - accuracy: 0.9063\nEpoch 8/15\n1253/1253 [==============================] - 10s 8ms/step - loss: 4.1613 - accuracy: 0.9016\nEpoch 9/15\n1253/1253 [==============================] - 3s 3ms/step - loss: 2.2076 - accuracy: 0.9190\nEpoch 10/15\n1253/1253 [==============================] - 3s 2ms/step - loss: 0.7747 - accuracy: 0.9393\nEpoch 11/15\n1253/1253 [==============================] - 3s 2ms/step - loss: 0.4939 - accuracy: 0.9345\nEpoch 12/15\n1253/1253 [==============================] - 2s 2ms/step - loss: 1.0025 - accuracy: 0.9288\nEpoch 13/15\n1253/1253 [==============================] - 3s 2ms/step - loss: 0.6430 - accuracy: 0.9360\nEpoch 14/15\n1253/1253 [==============================] - 3s 2ms/step - loss: 1.2050 - accuracy: 0.9245\nEpoch 15/15\n1253/1253 [==============================] - 2s 2ms/step - loss: 0.6428 - accuracy: 0.9355\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x632b34bd0>"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "model.fit(train_dataset, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_6 (Dense)              multiple                  50        \n_________________________________________________________________\ndense_7 (Dense)              multiple                  110       \n_________________________________________________________________\ndense_8 (Dense)              multiple                  11        \n=================================================================\nTotal params: 171\nTrainable params: 171\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# Display the model's architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'normed_train_data' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-9e7bc27b9c2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexample_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormed_train_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mexample_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mexample_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'normed_train_data' is not defined"
     ]
    }
   ],
   "source": [
    "example_batch = normed_train_data[:10]\n",
    "example_result = model.predict(example_batch)\n",
    "example_result\n",
    "print(example_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
    }
   ],
   "source": [
    "model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "del model  # deletes the existing model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "model = tf.keras.models.load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict()"
   ]
  }
 ]
}